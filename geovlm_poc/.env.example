# =============================================================================
# ФАЙЛ ПРИКЛАДУ НАЛАШТУВАНЬ ОТОЧЕННЯ ДЛЯ geovlm_poc
# =============================================================================
# Скопіюйте цей файл як .env та заповніть значення відповідно до вашої конфігурації
# cp .env.example .env

# =============================================================================
# НАЛАШТУВАННЯ НАРІЗКИ ТАЙЛІВ (Tiling)
# =============================================================================

# Розмір тайла в пікселях. Визначає, на які квадратні частини буде розбито
# супутникове зображення для обробки. Великі тайли = менше обробок, але більше
# пам'яті. Малі тайли = більше обробок, але менше пам'яті. Рекомендовано 1024
# для щільної міської забудови.
# Впливає на: ImageTiler (tiling.py), cmd_analyze (cli.py)
# За замовчуванням: 1024
TILE_SIZE=1024

# Перекриття тайлів в пікселях. Визначає, на скільки пікселів перекриваються
# сусідні тайли. Необхідно для коректного виявлення об'єктів на межах тайлів.
# Більше перекриття = краще виявлення на краях, але більше обробок та можливі
# дублікати (які видаляє GeoAggregator через NMS_IOU).
# Впливає на: ImageTiler (tiling.py), cmd_analyze (cli.py)
# За замовчуванням: 256
OVERLAP=256

# =============================================================================
# НАЛАШТУВАННЯ ФІЛЬТРАЦІЇ ТАЙЛІВ (Gate - відсіювання непотрібних тайлів)
# =============================================================================

# Режим фільтрації тайлів перед подальшою обробкою. Дозволяє відсіяти "порожні"
# тайли (ліси, поля, вода, хмари) для економії VLM-запитів та часу обробки.
# Можливі значення:
#   - "heuristic": швидкий метод на основі edge density та entropy (без додаткових залежностей)
#   - "clip": використовує CLIP модель для семантичного відсіювання (потрібен open_clip_torch)
#   - "cnn": використовує навчену CNN модель (потрібен torch, torchvision та CNN_GATE_CKPT)
# Впливає на: _build_gate() (cli.py), вибір gate в cmd_analyze (cli.py)
# За замовчуванням: "heuristic"
GATE=heuristic

# -----------------------------------------------------------------------------
# Параметри для Heuristic Gate (GATE=heuristic)
# -----------------------------------------------------------------------------

# Мінімальний комбінований score (0.0-1.0) для тайла, щоб він пройшов фільтрацію.
# Score розраховується як 0.6 * normalized_edge_density + 0.4 * normalized_entropy.
# Вищі значення = більш строга фільтрація (лишаються лише найбільш "цікаві" тайли).
# Впливає на: HeuristicGate.__init__ (gates.py), HeuristicGate.keep() (gates.py)
# За замовчуванням: 0.24
H_SCORE=0.24

# Мінімальна щільність країв (0.0-1.0) в тайлі. Вимірює кількість виявлених
# країв через алгоритм Canny. Високі значення = багато структур (будівлі, дороги).
# Впливає на: HeuristicGate.__init__ (gates.py), HeuristicGate.keep() (gates.py)
# За замовчуванням: 0.05
H_EDGE=0.05

# Мінімальна ентропія зображення (біти). Вимірює різноманітність пікселів.
# Високі значення = багато різних кольорів та текстур (характерно для забудови).
# Низькі значення = однорідні області (поля, вода, хмари).
# Впливає на: HeuristicGate.__init__ (gates.py), HeuristicGate.keep() (gates.py)
# За замовчуванням: 3.2
H_ENT=3.2

# -----------------------------------------------------------------------------
# Параметри для CLIP Gate (GATE=clip)
# -----------------------------------------------------------------------------

# Поріг score для CLIP gate (float). CLIP порівнює тайл з текстовими описами
# "цікавих" (dense urban area, buildings, parking lots, industrial sites) та
# "нецікавих" (forest, fields, water, clouds) сцен. Score = keep_similarity - drop_similarity.
# Якщо score >= CLIP_GATE_THR, тайл проходить фільтрацію.
# Вищі значення = більш строга фільтрація.
# Впливає на: CLIPGate.__init__ (gates.py), CLIPGate.keep() (gates.py)
# За замовчуванням: 0.15
CLIP_GATE_THR=0.15

# Пристрій для CLIP моделі. Можливі значення: "cpu", "cuda", "cuda:0", тощо.
# Використання GPU значно прискорює обробку CLIP gate.
# Впливає на: CLIPGate.__init__ (gates.py), завантаження моделі CLIP
# За замовчуванням: "cpu"
CLIP_DEVICE=cpu

# Модель і pretrained-ваги для open_clip (див. open_clip.available_models()).
# Приклади: ViT-B-32 + openai, ViT-L-14 + laion2b_s32b_b82k.
CLIP_MODEL=ViT-B-32
CLIP_PRETRAINED=openai

# Списки промптів для CLIP gate. Використовуйте розділювач "|" або ",".
# Keep — що вважається "цікавим" тайлом; Drop — що відсікається.
# Рекомендація: короткі конкретні фрази, додавайте "вид зверху/супутниковий".
# Впливає на: CLIPGate.__init__ (gates.py), CLIPGate.keep() (gates.py)
CLIP_KEEP_PROMPTS=dense urban area|buildings and roads|parking lot with many cars|industrial site
CLIP_DROP_PROMPTS=forest|agricultural field|water surface|clouds

# -----------------------------------------------------------------------------
# Параметри для CNN Gate (GATE=cnn)
# -----------------------------------------------------------------------------

# Шлях до файлу чекпойнту навченої CNN моделі (обов'язково для GATE=cnn).
# Модель - це MobileNetV3-small з одним вихідним нейроном для бінарної класифікації.
# Модель повинна бути збережена через torch.save() як state_dict.
# Впливає на: CNNGate.__init__ (gates.py), завантаження CNN моделі
# За замовчуванням: не встановлено (потрібно встановити для GATE=cnn)
CNN_GATE_CKPT=

# Поріг ймовірності для CNN gate (0.0-1.0). CNN повертає ймовірність, що тайл
# "цікавий". Якщо prob >= CNN_GATE_THR, тайл проходить фільтрацію.
# Впливає на: CNNGate.__init__ (gates.py), CNNGate.keep() (gates.py)
# За замовчуванням: 0.5
CNN_GATE_THR=0.5

# Пристрій для CNN моделі. Можливі значення: "cpu", "cuda", "cuda:0", тощо.
# Впливає на: CNNGate.__init__ (gates.py), завантаження CNN моделі
# За замовчуванням: "cpu"
CNN_DEVICE=cpu

# =============================================================================
# НАЛАШТУВАННЯ ДЕТЕКТОРА ОБ'ЄКТІВ (YOLO)
# =============================================================================

# Шлях до файлу моделі YOLO або назва стандартної моделі Ultralytics YOLO.
# Можна використовувати:
#   - Власну модель: "/path/to/your/yolo_model.pt"
#   - Стандартні моделі: "yolo12n.pt", "yolo12s.pt", "yolo12m.pt", "yolo12l.pt", "yolo12x.pt"
# Модель повинна бути встановлена через ultralytics або доступна локально.
# Впливає на: YOLODetector.__init__ (detector.py), YOLODetector._lazy() (detector.py)
# За замовчуванням: "yolo12n.pt"
YOLO_MODEL=yolo12n.pt

# Поріг впевненості (confidence threshold) для детекцій YOLO (0.0-1.0).
# Лише детекції з confidence >= YOLO_CONF будуть прийняті. Вищі значення =
# менше помилкових спраць (false positives), але можливе пропускання слабких детекцій.
# Впливає на: YOLODetector.__init__ (detector.py), YOLODetector.detect() (detector.py)
# За замовчуванням: 0.25
YOLO_CONF=0.25

# =============================================================================
# НАЛАШТУВАННЯ ГЕО-АГРЕГАЦІЇ (прибирання дублікатів об'єктів)
# =============================================================================

# Поріг Intersection over Union (IoU) для Non-Maximum Suppression при агрегації
# гео-об'єктів (0.0-1.0). Якщо два об'єкти одного класу мають IoU >= NMS_IOU,
# об'єкт з нижчою впевненістю видаляється (дублікат з перекриття тайлів).
# Вищі значення = менше видалень (допускається більше перекриття).
# Нижчі значення = більше видалень (строгіше прибирання дублікатів).
# Впливає на: GeoAggregator.__init__ (geo.py), GeoAggregator.geo_nms() (geo.py)
# За замовчуванням: 0.6
NMS_IOU=0.6

# =============================================================================
# НАЛАШТУВАННЯ VLM (Vision Language Model) - додавання семантики
# =============================================================================

# Базовий URL API для VLM моделі (обов'язково для команди analyze).
# Має бути OpenAI-сумісний endpoint з підтримкою /chat/completions.
# Приклади:
#   - OpenAI: "https://api.openai.com/v1"
#   - Локальна модель: "http://localhost:8011/v1"
#   - Власний сервер: "http://gpu-test.silly.billy:8011/v1"
# Впливає на: VLMAnnotator.__init__ (vlm.py), cmd_analyze (cli.py)
# За замовчуванням: не встановлено (обов'язково)
VLM_BASE_URL=

# API ключ для доступу до VLM API (обов'язково для команди analyze).
# Для деяких локальних моделей може бути "DUMMY_KEY" або будь-яке значення,
# якщо сервер не перевіряє авторизацію.
# Впливає на: VLMAnnotator.__init__ (vlm.py), VLMAnnotator.annotate() (vlm.py)
# За замовчуванням: не встановлено (обов'язково)
VLM_API_KEY=

# Назва VLM моделі для використання. Залежить від вашого API провайдера.
# Приклади:
#   - OpenAI: "gpt-4o", "gpt-4o-mini", "gpt-4-vision-preview"
#   - Локальні моделі: "qwen3-vl", "llava", тощо
# Впливає на: VLMAnnotator.__init__ (vlm.py), VLMAnnotator.annotate() (vlm.py)
# За замовчуванням: "gpt-4o"
VLM_MODEL=gpt-4o

# Кількість одночасних асинхронних запитів до VLM API (1-20+).
# Вищі значення = швидша обробка, але більше навантаження на API та можливі
# rate limiting помилки. Рекомендовано 4-8 для більшості API, до 10-15 для
# локальних серверів.
# Впливає на: VLMAnnotator.__init__ (vlm.py), asyncio.Semaphore в VLMAnnotator
# За замовчуванням: 6
VLM_CONCURRENCY=6

# =============================================================================
# НАЛАШТУВАННЯ ВИЯВЛЕННЯ ЗМІН (Change Detection)
# =============================================================================

# Поріг Intersection over Union (IoU) для співставлення об'єктів між двома датами
# при виявленні змін (0.0-1.0). Об'єкти з однаковим label та IoU >= MATCH_IOU
# вважаються одним і тим самим об'єктом. Потім перевіряється, чи вони змінилися
# (modified) або залишилися без змін.
# Вищі значення = строгіше співставлення (менше false matches).
# Нижчі значення = більше співставлень (можливі помилки при геометричних зсувах).
# Рекомендовано 0.3-0.4 для щільної забудови з невеликими зсувами.
# Впливає на: ChangeDetector.__init__ (change.py), ChangeDetector.diff() (change.py)
# За замовчуванням: 0.35
MATCH_IOU=0.35

# Толерантність буферу в метрах для пошуку кандидатів при change detection.
# При співставленні об'єктів з date A до date B, система шукає кандидатів в
# радіусі BUFFER_TOL метрів від об'єкта з date A. Потім серед них вибирається
# найкращий за IoU. Необхідно для компенсації геометричних зсувів між знімками.
# Важливо: працює в метрах, тому CRS повинен бути метричним (не EPSG:4326).
# Впливає на: ChangeDetector.__init__ (change.py), ChangeDetector.diff() (change.py)
# За замовчуванням: 4.0
BUFFER_TOL=4.0

# Радіус кластеризації транспортних засобів в метрах для виявлення груп змін.
# Використовується для визначення, чи змінилася кількість транспортних засобів
# у групі (наприклад, на парковці). Якщо різниця в кількості сусідніх транспортних
# засобів >= 6 в межах VEH_R, об'єкт позначається як modified.
# Впливає на: ChangeDetector.__init__ (change.py), _vehicle_group_sizes() (change.py)
# За замовчуванням: 25.0
VEH_R=25.0

# =============================================================================
# НАЛАШТУВАННЯ EMBEDDINGS ТА СЕМАНТИЧНОГО ІНДЕКСУ
# =============================================================================

# Базовий URL API для embeddings моделі (обов'язково для команд build-index та search).
# Має бути OpenAI-сумісний endpoint з підтримкою /embeddings.
# Приклади:
#   - OpenAI: "https://api.openai.com/v1"
#   - Локальна модель: "http://localhost:8022/v1"
#   - Власний сервер: "http://gpu-test.silly.billy:8022/v1"
# Впливає на: EmbeddingClient.__init__ (semantic_index.py), cmd_build_index(), cmd_search() (cli.py)
# За замовчуванням: не встановлено (обов'язково для build-index та search)
EMB_BASE_URL=

# API ключ для доступу до embeddings API (обов'язково для команд build-index та search).
# Для деяких локальних моделей може бути "DUMMY_KEY" або будь-яке значення,
# якщо сервер не перевіряє авторизацію.
# Впливає на: EmbeddingClient.__init__ (semantic_index.py), EmbeddingClient.embed() (semantic_index.py)
# За замовчуванням: не встановлено (обов'язково для build-index та search)
EMB_API_KEY=

# Назва embeddings моделі для використання. Залежить від вашого API провайдера.
# Приклади:
#   - OpenAI: "text-embedding-3-large", "text-embedding-3-small", "text-embedding-ada-002"
#   - Локальні моделі: "multilingual-embeddings", "sentence-transformers/all-MiniLM-L6-v2", тощо
# Впливає на: EmbeddingClient.__init__ (semantic_index.py), EmbeddingClient.embed() (semantic_index.py)
# За замовчуванням: "text-embedding-3-large"
EMB_MODEL=text-embedding-3-large

# Кількість топ-результатів для повернення при семантичному пошуку (1-100+).
# Визначає, скільки найбільш релевантних об'єктів або змін поверне команда search.
# Впливає на: cmd_search() (cli.py), SemanticSearcher.query() (semantic_index.py)
# За замовчуванням: 10
TOP_K=10
